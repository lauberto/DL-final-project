{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt install -y wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/RossiyaSegodnya/ria_news_dataset/raw/master/ria.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt install gzip --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gunzip ria.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removenewline(text):\n",
    "    cleann = re.compile(r'\\n')\n",
    "    cleantext = re.sub(cleann, '', text)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [json.loads(line) for line in open('ria.json', 'r', encoding='utf-8')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '<p><strong></strong></p>\\n<p><strong>москва, 31 янв - риа новости.</strong> большая часть из 33 детей, которых граждане сша пытались вывезти из гаити в организованный в доминиканской республике приют, не являются сиротами, сообщает в воскресенье <a href=\"http://www.afp.com\" target=\"_blank\">агентство франс пресс</a> со ссылкой на заявление представителя международной организации \"детские деревни sos\" (sos children\\'s village), оказывающей помощь детям, оставшимся без родителей</p>\\n<p>как заявила агентству патрисия варгас (patricia vargas), курирующая программы \"детских деревень sos\" в центральной америке, мексике и на карибах, поговорив с детьми она выяснила, что родители многих из них живы. некоторые дети смогли назвать свои домашние адреса и номера телефонов, что дает возможность связаться с их родителями.</p>\\n<p>в это воскресенье <a href=\"http://rian.ru/society/20100131/207037914.html\" target=\"_blank\">гаитянская полиция задержала десятерых граждан сша</a>, подозреваемых в попытке без разрешения вывезти более 30 детей в доминиканскую республику.</p>\\n<p>представитель баптистской церкви в городе меридиан американского штата айдахо шон лэнкфорд (sean lankford) заявил, что задержанные прибыли на гаити в составе группы, помогающей детям, которые остались без родителей после разрушительного землетрясения 12 января.</p>\\n<p>лэнкфорд также сообщил, что в числе задержанных его дочь и жена, и они думали, что у них имеются все необходимые документы, позволяющие вывезти детей в организованный в доминиканской республике приют.</p>\\n<p>в настоящее время все эти дети, за исключением маленькой девочки, страдающей от истощения, которая была госпитализирована, находятся в благотворительном центре организации в городе круа-де-букет (croix des bouquets), расположенном в 12 километрах к северо-востоку от столицы гаити порт-о-пренса.</p>\\n<p>по словам варгас, точный возраст малышки не известен, врачи полагают, что ей около 7 месяцев.</p>\\n<p>центр \"детских деревень sos\" на гаити юридически не является сиротским приютом и не отдает детей на усыновление.</p>\\n<p><em><strong>ранее гаитянские интернет-ресурсы сообщали, что</strong></em> <strong><a href=\"http://www.rian.ru/society/20100128/206736391.html\" target=\"_blank\">за  детьми, оставшимися сиротами после землетрясения, охотятся педофилы и торговцы  людьми &gt;&gt;</a></strong></p>\\n<p>как отмечает франс пресс, после разгула стихии на гаити были установлены новые правила усыновления, согласно которым премьер-министр страны жан-макс бельрив должен лично разрешить вывоз сирот. целью подобных мер является пресечение попыток незаконного вывоза детей для преступных целей в условиях хаоса, царящего в стране после разгула стихии.</p>\\n<p>по данным ответственных лиц на гаити, тысячи детей могли быть разлучены с родителями или лишиться их в результате <a href=\"http://www.rian.ru/trend/earthquake_haiti_13012010/\" target=\"_blank\">двух землетрясений магнитудой 7 и 5,9</a>, произошедших у побережья этого островного государства 12 января.</p>',\n",
       "  'title': 'большинство детей, которых пытались увезти в сша из гаити, не сироты'},\n",
       " {'text': '<p><strong></strong></p>\\n<p><strong>киев, 31 янв - риа новости, марина шмаюн.</strong> премьер-министр украины, кандидат в президенты юлия тимошенко в воскресенье в прямом эфире <a href=\"http://www.1plus1.ua/\" target=\"_blank\">украинского телеканала 1+1</a> заявила, что в случае ее победы на выборах президента юрий луценко будет работать в ее команде.</p>\\n<p>17 января в украине состоялся первый тур выборов президента, по итогам которого <a href=\"http://rian.ru/politics/20100125/206201353.html\" target=\"_blank\">виктор янукович набрал 35,32% голосов, а премьер-министр страны юлия тимошенко оказалась на втором месте с результатом 25,05%</a>. второй тур выборов президента украины <a href=\"http://www.rian.ru/trend/ukraine_election_18012010/\" target=\"_blank\">состоится 7 февраля</a>.</p>\\n<p>парламент украины по инициативе партии регионов 28 января <a href=\"http://rian.ru/trend/ukr_lutsenko_retired_28012010/\" target=\"_blank\">отправил в отставку главу мвд юрия луценко</a>, однако премьер-министр юлия тимошенко <a href=\"http://rian.ru/international_justice/20100129/206834215.html\" target=\"_blank\">внесла в кабмин его кандидатуру на утверждение первым замминистра внутренних дел</a> с полномочиями и.о. министра. правительство единогласно поддержало это предложение. партия регионов оспорила это решение кабмина в суде.</p>\\n<p>\"что касается новых назначений, то знаете, как народная мудрость гласит: не нужно говорить \"гоп\", пока еще не произошло событие. потому я считаю, что нужно сначала выиграть выборы, обсудить все вопросы создания новой команды, и я убеждена, что юрий луценко в команде будет работать\", - сказала тимошенко.</p>',\n",
       "  'title': 'луценко будет работать в команде тимошенко, если она победит в выборах'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'text': cleanhtml(line['text']), 'title': cleanhtml(line['title'])} for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '\\nмосква, 31 янв - риа новости. большая часть из 33 детей, которых граждане сша пытались вывезти из гаити в организованный в доминиканской республике приют, не являются сиротами, сообщает в воскресенье агентство франс пресс со ссылкой на заявление представителя международной организации \"детские деревни sos\" (sos children\\'s village), оказывающей помощь детям, оставшимся без родителей\\nкак заявила агентству патрисия варгас (patricia vargas), курирующая программы \"детских деревень sos\" в центральной америке, мексике и на карибах, поговорив с детьми она выяснила, что родители многих из них живы. некоторые дети смогли назвать свои домашние адреса и номера телефонов, что дает возможность связаться с их родителями.\\nв это воскресенье гаитянская полиция задержала десятерых граждан сша, подозреваемых в попытке без разрешения вывезти более 30 детей в доминиканскую республику.\\nпредставитель баптистской церкви в городе меридиан американского штата айдахо шон лэнкфорд (sean lankford) заявил, что задержанные прибыли на гаити в составе группы, помогающей детям, которые остались без родителей после разрушительного землетрясения 12 января.\\nлэнкфорд также сообщил, что в числе задержанных его дочь и жена, и они думали, что у них имеются все необходимые документы, позволяющие вывезти детей в организованный в доминиканской республике приют.\\nв настоящее время все эти дети, за исключением маленькой девочки, страдающей от истощения, которая была госпитализирована, находятся в благотворительном центре организации в городе круа-де-букет (croix des bouquets), расположенном в 12 километрах к северо-востоку от столицы гаити порт-о-пренса.\\nпо словам варгас, точный возраст малышки не известен, врачи полагают, что ей около 7 месяцев.\\nцентр \"детских деревень sos\" на гаити юридически не является сиротским приютом и не отдает детей на усыновление.\\nранее гаитянские интернет-ресурсы сообщали, что за  детьми, оставшимися сиротами после землетрясения, охотятся педофилы и торговцы  людьми \\nкак отмечает франс пресс, после разгула стихии на гаити были установлены новые правила усыновления, согласно которым премьер-министр страны жан-макс бельрив должен лично разрешить вывоз сирот. целью подобных мер является пресечение попыток незаконного вывоза детей для преступных целей в условиях хаоса, царящего в стране после разгула стихии.\\nпо данным ответственных лиц на гаити, тысячи детей могли быть разлучены с родителями или лишиться их в результате двух землетрясений магнитудой 7 и 5,9, произошедших у побережья этого островного государства 12 января.',\n",
       "  'title': 'большинство детей, которых пытались увезти в сша из гаити, не сироты'},\n",
       " {'text': '\\nкиев, 31 янв - риа новости, марина шмаюн. премьер-министр украины, кандидат в президенты юлия тимошенко в воскресенье в прямом эфире украинского телеканала 1+1 заявила, что в случае ее победы на выборах президента юрий луценко будет работать в ее команде.\\n17 января в украине состоялся первый тур выборов президента, по итогам которого виктор янукович набрал 35,32% голосов, а премьер-министр страны юлия тимошенко оказалась на втором месте с результатом 25,05%. второй тур выборов президента украины состоится 7 февраля.\\nпарламент украины по инициативе партии регионов 28 января отправил в отставку главу мвд юрия луценко, однако премьер-министр юлия тимошенко внесла в кабмин его кандидатуру на утверждение первым замминистра внутренних дел с полномочиями и.о. министра. правительство единогласно поддержало это предложение. партия регионов оспорила это решение кабмина в суде.\\n\"что касается новых назначений, то знаете, как народная мудрость гласит: не нужно говорить \"гоп\", пока еще не произошло событие. потому я считаю, что нужно сначала выиграть выборы, обсудить все вопросы создания новой команды, и я убеждена, что юрий луценко в команде будет работать\", - сказала тимошенко.',\n",
       "  'title': 'луценко будет работать в команде тимошенко, если она победит в выборах'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPE tokenization with YouTokenToMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtokentome in /opt/conda/lib/python3.8/site-packages (1.0.6)\r\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.8/site-packages (from youtokentome) (7.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install youtokentome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtokentome as yttm\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('for_bpe.txt', 'w', encoding='utf-8') as f:\n",
    "#     for line in data:\n",
    "#         f.write(line['text'] + '\\n' + line['title'] + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры\n",
    "vocab_size = 30_000\n",
    "model_path = 'pretrained_bpe_lm.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# yttm.BPE.train(data='for_bpe.txt', vocab_size=vocab_size, model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = yttm.BPE(model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003869"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_texts = len(data)\n",
    "total_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3922/3922 [01:58<00:00, 33.22it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = []\n",
    "tokenized_titles = []\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "for i_batch in tqdm(range(math.ceil(total_texts / batch_size))):\n",
    "    \n",
    "    tokenized_texts.extend(tokenizer.encode(\n",
    "        list(df.text[i_batch*batch_size:(i_batch+1)*batch_size]), bos=True, eos=True))\n",
    "    \n",
    "    tokenized_titles.extend(tokenizer.encode(\n",
    "        list(df.title[i_batch*batch_size:(i_batch+1)*batch_size]), bos=True, eos=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = zip(tokenized_texts, tokenized_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{'text': line[0], 'title': line[1]} for line in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': [2,\n",
       "   885,\n",
       "   2973,\n",
       "   2996,\n",
       "   577,\n",
       "   676,\n",
       "   792,\n",
       "   5863,\n",
       "   2074,\n",
       "   614,\n",
       "   6182,\n",
       "   6043,\n",
       "   1755,\n",
       "   7806,\n",
       "   1127,\n",
       "   10156,\n",
       "   12065,\n",
       "   537,\n",
       "   614,\n",
       "   20083,\n",
       "   496,\n",
       "   26487,\n",
       "   496,\n",
       "   23885,\n",
       "   11159,\n",
       "   7421,\n",
       "   578,\n",
       "   2139,\n",
       "   554,\n",
       "   3849,\n",
       "   23096,\n",
       "   10852,\n",
       "   1387,\n",
       "   496,\n",
       "   3554,\n",
       "   2221,\n",
       "   7583,\n",
       "   4707,\n",
       "   549,\n",
       "   5402,\n",
       "   518,\n",
       "   4404,\n",
       "   5394,\n",
       "   3943,\n",
       "   2190,\n",
       "   12908,\n",
       "   879,\n",
       "   18474,\n",
       "   1340,\n",
       "   3183,\n",
       "   32,\n",
       "   9603,\n",
       "   3183,\n",
       "   7916,\n",
       "   20926,\n",
       "   55,\n",
       "   1697,\n",
       "   9829,\n",
       "   3947,\n",
       "   9703,\n",
       "   15906,\n",
       "   988,\n",
       "   4466,\n",
       "   2367,\n",
       "   3577,\n",
       "   1162,\n",
       "   17846,\n",
       "   6737,\n",
       "   2563,\n",
       "   540,\n",
       "   962,\n",
       "   11862,\n",
       "   760,\n",
       "   5765,\n",
       "   4774,\n",
       "   4345,\n",
       "   6128,\n",
       "   4284,\n",
       "   646,\n",
       "   11,\n",
       "   13992,\n",
       "   3691,\n",
       "   28343,\n",
       "   3080,\n",
       "   3947,\n",
       "   1554,\n",
       "   69,\n",
       "   3213,\n",
       "   988,\n",
       "   6998,\n",
       "   28952,\n",
       "   2370,\n",
       "   12908,\n",
       "   750,\n",
       "   5271,\n",
       "   922,\n",
       "   1340,\n",
       "   3183,\n",
       "   32,\n",
       "   496,\n",
       "   7151,\n",
       "   5732,\n",
       "   2145,\n",
       "   6410,\n",
       "   693,\n",
       "   507,\n",
       "   518,\n",
       "   19881,\n",
       "   724,\n",
       "   993,\n",
       "   510,\n",
       "   16479,\n",
       "   13,\n",
       "   497,\n",
       "   15915,\n",
       "   1277,\n",
       "   5823,\n",
       "   1461,\n",
       "   595,\n",
       "   9489,\n",
       "   5412,\n",
       "   614,\n",
       "   2161,\n",
       "   830,\n",
       "   11321,\n",
       "   4142,\n",
       "   6228,\n",
       "   7114,\n",
       "   10941,\n",
       "   1341,\n",
       "   7789,\n",
       "   2092,\n",
       "   6897,\n",
       "   653,\n",
       "   507,\n",
       "   13848,\n",
       "   20827,\n",
       "   25,\n",
       "   595,\n",
       "   8584,\n",
       "   2736,\n",
       "   6046,\n",
       "   798,\n",
       "   497,\n",
       "   1078,\n",
       "   2442,\n",
       "   17859,\n",
       "   496,\n",
       "   661,\n",
       "   3554,\n",
       "   12270,\n",
       "   1471,\n",
       "   19394,\n",
       "   4173,\n",
       "   13402,\n",
       "   2005,\n",
       "   21778,\n",
       "   1443,\n",
       "   3831,\n",
       "   10844,\n",
       "   496,\n",
       "   16644,\n",
       "   962,\n",
       "   9175,\n",
       "   12065,\n",
       "   537,\n",
       "   969,\n",
       "   1695,\n",
       "   2021,\n",
       "   496,\n",
       "   23885,\n",
       "   511,\n",
       "   1522,\n",
       "   1524,\n",
       "   3357,\n",
       "   1442,\n",
       "   918,\n",
       "   7699,\n",
       "   10288,\n",
       "   6063,\n",
       "   496,\n",
       "   2928,\n",
       "   637,\n",
       "   29786,\n",
       "   511,\n",
       "   7256,\n",
       "   9491,\n",
       "   9777,\n",
       "   533,\n",
       "   602,\n",
       "   829,\n",
       "   658,\n",
       "   2124,\n",
       "   41,\n",
       "   1410,\n",
       "   28389,\n",
       "   623,\n",
       "   8291,\n",
       "   1295,\n",
       "   2846,\n",
       "   9029,\n",
       "   74,\n",
       "   12749,\n",
       "   43,\n",
       "   2525,\n",
       "   595,\n",
       "   22577,\n",
       "   7446,\n",
       "   518,\n",
       "   20083,\n",
       "   496,\n",
       "   4772,\n",
       "   11890,\n",
       "   5940,\n",
       "   2367,\n",
       "   1162,\n",
       "   17846,\n",
       "   980,\n",
       "   6845,\n",
       "   962,\n",
       "   11862,\n",
       "   795,\n",
       "   29967,\n",
       "   7810,\n",
       "   1542,\n",
       "   11216,\n",
       "   2124,\n",
       "   41,\n",
       "   1410,\n",
       "   28389,\n",
       "   859,\n",
       "   3201,\n",
       "   595,\n",
       "   496,\n",
       "   1516,\n",
       "   11230,\n",
       "   803,\n",
       "   10335,\n",
       "   507,\n",
       "   1813,\n",
       "   9231,\n",
       "   507,\n",
       "   1119,\n",
       "   3142,\n",
       "   1236,\n",
       "   595,\n",
       "   535,\n",
       "   2161,\n",
       "   19411,\n",
       "   725,\n",
       "   7501,\n",
       "   12851,\n",
       "   5332,\n",
       "   1645,\n",
       "   12065,\n",
       "   537,\n",
       "   2021,\n",
       "   496,\n",
       "   26487,\n",
       "   496,\n",
       "   23885,\n",
       "   11159,\n",
       "   7421,\n",
       "   578,\n",
       "   8915,\n",
       "   496,\n",
       "   2323,\n",
       "   964,\n",
       "   725,\n",
       "   1218,\n",
       "   17815,\n",
       "   547,\n",
       "   14822,\n",
       "   7903,\n",
       "   917,\n",
       "   11800,\n",
       "   1239,\n",
       "   19946,\n",
       "   2367,\n",
       "   576,\n",
       "   1192,\n",
       "   22233,\n",
       "   1507,\n",
       "   1328,\n",
       "   28407,\n",
       "   25,\n",
       "   3598,\n",
       "   496,\n",
       "   6843,\n",
       "   5430,\n",
       "   3268,\n",
       "   2190,\n",
       "   496,\n",
       "   2928,\n",
       "   2077,\n",
       "   7,\n",
       "   16940,\n",
       "   754,\n",
       "   2182,\n",
       "   12554,\n",
       "   2257,\n",
       "   10037,\n",
       "   2299,\n",
       "   1654,\n",
       "   7820,\n",
       "   66,\n",
       "   7857,\n",
       "   3760,\n",
       "   57,\n",
       "   988,\n",
       "   17908,\n",
       "   496,\n",
       "   1542,\n",
       "   5807,\n",
       "   555,\n",
       "   14919,\n",
       "   628,\n",
       "   576,\n",
       "   2980,\n",
       "   20083,\n",
       "   4981,\n",
       "   4310,\n",
       "   1687,\n",
       "   920,\n",
       "   3179,\n",
       "   510,\n",
       "   1706,\n",
       "   4284,\n",
       "   646,\n",
       "   1610,\n",
       "   629,\n",
       "   2256,\n",
       "   11915,\n",
       "   14103,\n",
       "   2426,\n",
       "   554,\n",
       "   1812,\n",
       "   10498,\n",
       "   7822,\n",
       "   14338,\n",
       "   595,\n",
       "   4858,\n",
       "   1191,\n",
       "   1108,\n",
       "   12728,\n",
       "   3441,\n",
       "   12908,\n",
       "   750,\n",
       "   5271,\n",
       "   922,\n",
       "   1340,\n",
       "   3183,\n",
       "   32,\n",
       "   518,\n",
       "   20083,\n",
       "   28735,\n",
       "   554,\n",
       "   1596,\n",
       "   27407,\n",
       "   1267,\n",
       "   578,\n",
       "   34,\n",
       "   828,\n",
       "   507,\n",
       "   554,\n",
       "   7399,\n",
       "   515,\n",
       "   2021,\n",
       "   518,\n",
       "   9522,\n",
       "   16139,\n",
       "   1183,\n",
       "   12270,\n",
       "   1471,\n",
       "   20636,\n",
       "   27878,\n",
       "   1022,\n",
       "   17800,\n",
       "   595,\n",
       "   547,\n",
       "   28464,\n",
       "   6737,\n",
       "   6924,\n",
       "   540,\n",
       "   23096,\n",
       "   3002,\n",
       "   795,\n",
       "   4443,\n",
       "   6754,\n",
       "   6795,\n",
       "   14651,\n",
       "   28456,\n",
       "   877,\n",
       "   507,\n",
       "   2778,\n",
       "   1164,\n",
       "   20637,\n",
       "   760,\n",
       "   4516,\n",
       "   7583,\n",
       "   23924,\n",
       "   795,\n",
       "   687,\n",
       "   767,\n",
       "   523,\n",
       "   17528,\n",
       "   518,\n",
       "   20083,\n",
       "   1063,\n",
       "   9937,\n",
       "   3254,\n",
       "   7281,\n",
       "   9522,\n",
       "   6146,\n",
       "   2273,\n",
       "   4299,\n",
       "   4191,\n",
       "   1273,\n",
       "   8311,\n",
       "   9916,\n",
       "   1991,\n",
       "   5919,\n",
       "   516,\n",
       "   13,\n",
       "   2450,\n",
       "   7548,\n",
       "   17560,\n",
       "   23383,\n",
       "   23096,\n",
       "   2395,\n",
       "   5328,\n",
       "   9337,\n",
       "   2135,\n",
       "   1596,\n",
       "   7005,\n",
       "   1224,\n",
       "   22479,\n",
       "   17362,\n",
       "   5502,\n",
       "   522,\n",
       "   2021,\n",
       "   721,\n",
       "   2051,\n",
       "   590,\n",
       "   14424,\n",
       "   496,\n",
       "   5536,\n",
       "   1448,\n",
       "   5,\n",
       "   2559,\n",
       "   8360,\n",
       "   20,\n",
       "   1344,\n",
       "   496,\n",
       "   3719,\n",
       "   795,\n",
       "   687,\n",
       "   767,\n",
       "   523,\n",
       "   6859,\n",
       "   1676,\n",
       "   510,\n",
       "   1449,\n",
       "   2648,\n",
       "   590,\n",
       "   2927,\n",
       "   518,\n",
       "   12270,\n",
       "   4934,\n",
       "   1453,\n",
       "   2021,\n",
       "   4723,\n",
       "   1444,\n",
       "   687,\n",
       "   612,\n",
       "   2093,\n",
       "   497,\n",
       "   2442,\n",
       "   3131,\n",
       "   1074,\n",
       "   8843,\n",
       "   798,\n",
       "   1078,\n",
       "   496,\n",
       "   2011,\n",
       "   1632,\n",
       "   4443,\n",
       "   937,\n",
       "   9201,\n",
       "   1108,\n",
       "   507,\n",
       "   986,\n",
       "   3633,\n",
       "   25,\n",
       "   6248,\n",
       "   1318,\n",
       "   535,\n",
       "   11323,\n",
       "   1334,\n",
       "   6393,\n",
       "   598,\n",
       "   2986,\n",
       "   1542,\n",
       "   11216,\n",
       "   3],\n",
       "  'title': [2,\n",
       "   4159,\n",
       "   6043,\n",
       "   1755,\n",
       "   10156,\n",
       "   27519,\n",
       "   537,\n",
       "   496,\n",
       "   1127,\n",
       "   614,\n",
       "   12270,\n",
       "   4934,\n",
       "   554,\n",
       "   23096,\n",
       "   680,\n",
       "   3]},\n",
       " {'text': [2,\n",
       "   5311,\n",
       "   2973,\n",
       "   2996,\n",
       "   577,\n",
       "   676,\n",
       "   1185,\n",
       "   10528,\n",
       "   21287,\n",
       "   34,\n",
       "   1420,\n",
       "   4191,\n",
       "   4791,\n",
       "   9089,\n",
       "   496,\n",
       "   9773,\n",
       "   7289,\n",
       "   5979,\n",
       "   496,\n",
       "   3554,\n",
       "   496,\n",
       "   20497,\n",
       "   10637,\n",
       "   8639,\n",
       "   8269,\n",
       "   607,\n",
       "   89,\n",
       "   39,\n",
       "   8983,\n",
       "   595,\n",
       "   496,\n",
       "   3190,\n",
       "   1214,\n",
       "   5072,\n",
       "   518,\n",
       "   4303,\n",
       "   1546,\n",
       "   4444,\n",
       "   25017,\n",
       "   849,\n",
       "   3654,\n",
       "   496,\n",
       "   1214,\n",
       "   1439,\n",
       "   5011,\n",
       "   1768,\n",
       "   2108,\n",
       "   496,\n",
       "   5268,\n",
       "   8907,\n",
       "   1986,\n",
       "   1609,\n",
       "   3846,\n",
       "   10280,\n",
       "   510,\n",
       "   3124,\n",
       "   1859,\n",
       "   4004,\n",
       "   8048,\n",
       "   12476,\n",
       "   4897,\n",
       "   2966,\n",
       "   9376,\n",
       "   15612,\n",
       "   539,\n",
       "   4191,\n",
       "   1273,\n",
       "   7289,\n",
       "   5979,\n",
       "   9143,\n",
       "   518,\n",
       "   5751,\n",
       "   3117,\n",
       "   497,\n",
       "   9903,\n",
       "   1756,\n",
       "   6009,\n",
       "   45,\n",
       "   2393,\n",
       "   2432,\n",
       "   1609,\n",
       "   3846,\n",
       "   1546,\n",
       "   1376,\n",
       "   2008,\n",
       "   1108,\n",
       "   9921,\n",
       "   3008,\n",
       "   1376,\n",
       "   510,\n",
       "   11778,\n",
       "   2584,\n",
       "   3668,\n",
       "   2378,\n",
       "   2108,\n",
       "   19018,\n",
       "   496,\n",
       "   9764,\n",
       "   7808,\n",
       "   2326,\n",
       "   7572,\n",
       "   19417,\n",
       "   2708,\n",
       "   1336,\n",
       "   4191,\n",
       "   7289,\n",
       "   5979,\n",
       "   26664,\n",
       "   496,\n",
       "   20727,\n",
       "   803,\n",
       "   10548,\n",
       "   518,\n",
       "   23023,\n",
       "   5218,\n",
       "   8770,\n",
       "   4991,\n",
       "   2841,\n",
       "   497,\n",
       "   15743,\n",
       "   11775,\n",
       "   3476,\n",
       "   29,\n",
       "   2227,\n",
       "   21930,\n",
       "   4618,\n",
       "   538,\n",
       "   661,\n",
       "   5893,\n",
       "   29,\n",
       "   4701,\n",
       "   3668,\n",
       "   20783,\n",
       "   12362,\n",
       "   661,\n",
       "   1572,\n",
       "   23831,\n",
       "   496,\n",
       "   21586,\n",
       "   8687,\n",
       "   5024,\n",
       "   2779,\n",
       "   2220,\n",
       "   25881,\n",
       "   629,\n",
       "   21519,\n",
       "   760,\n",
       "   22162,\n",
       "   896,\n",
       "   3603,\n",
       "   664,\n",
       "   821,\n",
       "   3894,\n",
       "   59,\n",
       "   554,\n",
       "   2612,\n",
       "   5733,\n",
       "   5910,\n",
       "   18,\n",
       "   624,\n",
       "   1363,\n",
       "   1110,\n",
       "   554,\n",
       "   3044,\n",
       "   2333,\n",
       "   16883,\n",
       "   2856,\n",
       "   691,\n",
       "   8743,\n",
       "   595,\n",
       "   2612,\n",
       "   5466,\n",
       "   14750,\n",
       "   19040,\n",
       "   9055,\n",
       "   725,\n",
       "   2975,\n",
       "   4920,\n",
       "   3814,\n",
       "   13790,\n",
       "   507,\n",
       "   691,\n",
       "   4366,\n",
       "   7743,\n",
       "   25,\n",
       "   595,\n",
       "   4444,\n",
       "   25017,\n",
       "   496,\n",
       "   9111,\n",
       "   849,\n",
       "   3654,\n",
       "   624,\n",
       "   577,\n",
       "   2796,\n",
       "   22240,\n",
       "   3],\n",
       "  'title': [2,\n",
       "   25017,\n",
       "   849,\n",
       "   3654,\n",
       "   496,\n",
       "   9111,\n",
       "   15448,\n",
       "   1323,\n",
       "   1277,\n",
       "   2833,\n",
       "   10,\n",
       "   496,\n",
       "   4303,\n",
       "   3]}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 22 18:17:59 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.57       Driver Version: 450.57       CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  On   | 00000000:03:00.0 Off |                  N/A |\r\n",
      "|  0%   25C    P8    18W / 250W |      0MiB / 11177MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (3.3.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (8.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = np.array([len(x) for x in tokenized_texts])\n",
    "title_lengths = np.array([len(x) for x in tokenized_titles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(text_lengths, q=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(title_lengths, q=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "\n",
    "validation_start_index = int(len(data) * 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50193"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "max_len_texts = 880\n",
    "max_len_titles = 20\n",
    "\n",
    "pad_index = 0\n",
    "bos_index = 2\n",
    "eos_index = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, max_len_texts, max_len_titles, pad_index, bos_index, eos_index):\n",
    "        \n",
    "        self.data = data\n",
    "        \n",
    "        self.max_len_texts = max_len_texts\n",
    "        self.max_len_titles = max_len_titles\n",
    "        \n",
    "        self.pad_index = pad_index\n",
    "        self.bos_index = bos_index\n",
    "        self.eos_index = eos_index\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        x = self.data[index]['text'][:self.max_len_texts]\n",
    "        y = self.data[index]['title'][:self.max_len_titles]\n",
    "        \n",
    "        y_original = y[:]\n",
    "        y_to_predict = y[1:] + [self.eos_index]\n",
    "        \n",
    "        x_pads = [self.pad_index] * (self.max_len_texts - len(x))\n",
    "        y_pads = [self.pad_index] * (self.max_len_titles - len(y))\n",
    "        \n",
    "        x = torch.tensor(x + x_pads).long()\n",
    "        y_original = torch.tensor(y_original + y_pads).long()\n",
    "        y_to_predict = torch.tensor(y_to_predict + y_pads).long()\n",
    "        \n",
    "        return x, y_original, y_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': [2,\n",
       "   21462,\n",
       "   17202,\n",
       "   1542,\n",
       "   1291,\n",
       "   577,\n",
       "   676,\n",
       "   1185,\n",
       "   1899,\n",
       "   1003,\n",
       "   3346,\n",
       "   29,\n",
       "   1237,\n",
       "   21462,\n",
       "   502,\n",
       "   8558,\n",
       "   496,\n",
       "   3116,\n",
       "   2349,\n",
       "   530,\n",
       "   3871,\n",
       "   2508,\n",
       "   16036,\n",
       "   7706,\n",
       "   17163,\n",
       "   518,\n",
       "   5355,\n",
       "   3280,\n",
       "   12321,\n",
       "   2098,\n",
       "   25,\n",
       "   6667,\n",
       "   2227,\n",
       "   14961,\n",
       "   598,\n",
       "   5778,\n",
       "   6015,\n",
       "   2538,\n",
       "   1887,\n",
       "   510,\n",
       "   1449,\n",
       "   6360,\n",
       "   16270,\n",
       "   7797,\n",
       "   1128,\n",
       "   12871,\n",
       "   506,\n",
       "   21465,\n",
       "   3439,\n",
       "   518,\n",
       "   6223,\n",
       "   8641,\n",
       "   4391,\n",
       "   507,\n",
       "   1389,\n",
       "   502,\n",
       "   1867,\n",
       "   27225,\n",
       "   560,\n",
       "   6338,\n",
       "   1338,\n",
       "   17163,\n",
       "   518,\n",
       "   5670,\n",
       "   16116,\n",
       "   12321,\n",
       "   15750,\n",
       "   1608,\n",
       "   1197,\n",
       "   518,\n",
       "   6591,\n",
       "   2592,\n",
       "   590,\n",
       "   26401,\n",
       "   30,\n",
       "   555,\n",
       "   5103,\n",
       "   12965,\n",
       "   2121,\n",
       "   580,\n",
       "   3603,\n",
       "   3406,\n",
       "   1227,\n",
       "   9532,\n",
       "   497,\n",
       "   26422,\n",
       "   3949,\n",
       "   6104,\n",
       "   9550,\n",
       "   2121,\n",
       "   8889,\n",
       "   1128,\n",
       "   3654,\n",
       "   27472,\n",
       "   15063,\n",
       "   1896,\n",
       "   1755,\n",
       "   577,\n",
       "   6616,\n",
       "   2423,\n",
       "   12278,\n",
       "   496,\n",
       "   3620,\n",
       "   497,\n",
       "   5938,\n",
       "   12026,\n",
       "   590,\n",
       "   3132,\n",
       "   4268,\n",
       "   1119,\n",
       "   1128,\n",
       "   6100,\n",
       "   546,\n",
       "   5514,\n",
       "   2829,\n",
       "   568,\n",
       "   12217,\n",
       "   574,\n",
       "   1488,\n",
       "   496,\n",
       "   28532,\n",
       "   3541,\n",
       "   2213,\n",
       "   29,\n",
       "   510,\n",
       "   1449,\n",
       "   1694,\n",
       "   21462,\n",
       "   17202,\n",
       "   497,\n",
       "   7364,\n",
       "   11433,\n",
       "   6090,\n",
       "   602,\n",
       "   508,\n",
       "   4162,\n",
       "   32,\n",
       "   496,\n",
       "   6309,\n",
       "   2416,\n",
       "   710,\n",
       "   5081,\n",
       "   813,\n",
       "   518,\n",
       "   16536,\n",
       "   6321,\n",
       "   3444,\n",
       "   8737,\n",
       "   3486,\n",
       "   2836,\n",
       "   20245,\n",
       "   496,\n",
       "   3620,\n",
       "   496,\n",
       "   5342,\n",
       "   1334,\n",
       "   710,\n",
       "   12375,\n",
       "   518,\n",
       "   2287,\n",
       "   12588,\n",
       "   4090,\n",
       "   25026,\n",
       "   10267,\n",
       "   3305,\n",
       "   1364,\n",
       "   3],\n",
       "  'title': [2,\n",
       "   1237,\n",
       "   17994,\n",
       "   1848,\n",
       "   2349,\n",
       "   18506,\n",
       "   1535,\n",
       "   9413,\n",
       "   19127,\n",
       "   12363,\n",
       "   561,\n",
       "   8491,\n",
       "   896,\n",
       "   602,\n",
       "   12585,\n",
       "   3]},\n",
       " {'text': [2,\n",
       "   3823,\n",
       "   28186,\n",
       "   29987,\n",
       "   662,\n",
       "   15542,\n",
       "   1692,\n",
       "   24,\n",
       "   822,\n",
       "   1848,\n",
       "   5651,\n",
       "   4279,\n",
       "   10719,\n",
       "   880,\n",
       "   570,\n",
       "   946,\n",
       "   3324,\n",
       "   513,\n",
       "   25,\n",
       "   906,\n",
       "   4138,\n",
       "   2847,\n",
       "   12148,\n",
       "   6840,\n",
       "   19247,\n",
       "   18892,\n",
       "   4351,\n",
       "   4266,\n",
       "   2947,\n",
       "   13119,\n",
       "   7721,\n",
       "   1183,\n",
       "   23666,\n",
       "   595,\n",
       "   721,\n",
       "   11750,\n",
       "   12309,\n",
       "   1447,\n",
       "   20263,\n",
       "   16188,\n",
       "   10545,\n",
       "   849,\n",
       "   3358,\n",
       "   13927,\n",
       "   576,\n",
       "   4840,\n",
       "   570,\n",
       "   4065,\n",
       "   496,\n",
       "   4174,\n",
       "   11297,\n",
       "   10942,\n",
       "   529,\n",
       "   8880,\n",
       "   650,\n",
       "   3823,\n",
       "   28186,\n",
       "   6840,\n",
       "   9584,\n",
       "   5426,\n",
       "   721,\n",
       "   1197,\n",
       "   1132,\n",
       "   21616,\n",
       "   496,\n",
       "   3041,\n",
       "   16396,\n",
       "   2898,\n",
       "   4840,\n",
       "   574,\n",
       "   964,\n",
       "   10719,\n",
       "   1674,\n",
       "   7141,\n",
       "   496,\n",
       "   1907,\n",
       "   4327,\n",
       "   3984,\n",
       "   3233,\n",
       "   2932,\n",
       "   6087,\n",
       "   9850,\n",
       "   21671,\n",
       "   21858,\n",
       "   27647,\n",
       "   1817,\n",
       "   4090,\n",
       "   1231,\n",
       "   537,\n",
       "   519,\n",
       "   510,\n",
       "   642,\n",
       "   3938,\n",
       "   592,\n",
       "   1604,\n",
       "   3],\n",
       "  'title': [2, 24471, 4222, 11, 580, 2243, 497, 35, 21, 5085, 3]}]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': [2,\n",
       "   28138,\n",
       "   1347,\n",
       "   1233,\n",
       "   577,\n",
       "   676,\n",
       "   792,\n",
       "   21594,\n",
       "   5335,\n",
       "   13,\n",
       "   5939,\n",
       "   1257,\n",
       "   9461,\n",
       "   4711,\n",
       "   18096,\n",
       "   614,\n",
       "   12998,\n",
       "   496,\n",
       "   11019,\n",
       "   1163,\n",
       "   5510,\n",
       "   14776,\n",
       "   646,\n",
       "   798,\n",
       "   518,\n",
       "   8727,\n",
       "   2145,\n",
       "   1387,\n",
       "   8570,\n",
       "   2148,\n",
       "   3224,\n",
       "   2081,\n",
       "   8,\n",
       "   507,\n",
       "   19663,\n",
       "   12342,\n",
       "   4633,\n",
       "   26171,\n",
       "   542,\n",
       "   3098,\n",
       "   22053,\n",
       "   2988,\n",
       "   1245,\n",
       "   671,\n",
       "   496,\n",
       "   1003,\n",
       "   10804,\n",
       "   16588,\n",
       "   4249,\n",
       "   5335,\n",
       "   13,\n",
       "   662,\n",
       "   2148,\n",
       "   3224,\n",
       "   506,\n",
       "   718,\n",
       "   1259,\n",
       "   19392,\n",
       "   496,\n",
       "   3110,\n",
       "   5807,\n",
       "   576,\n",
       "   1124,\n",
       "   25987,\n",
       "   4464,\n",
       "   19749,\n",
       "   496,\n",
       "   4021,\n",
       "   518,\n",
       "   2023,\n",
       "   624,\n",
       "   577,\n",
       "   1275,\n",
       "   496,\n",
       "   2991,\n",
       "   28587,\n",
       "   14499,\n",
       "   16588,\n",
       "   2153,\n",
       "   7809,\n",
       "   29,\n",
       "   518,\n",
       "   15227,\n",
       "   1723,\n",
       "   1692,\n",
       "   1580,\n",
       "   496,\n",
       "   2330,\n",
       "   5335,\n",
       "   13,\n",
       "   681,\n",
       "   3799,\n",
       "   1142,\n",
       "   587,\n",
       "   3266,\n",
       "   11784,\n",
       "   1467,\n",
       "   29,\n",
       "   510,\n",
       "   10559,\n",
       "   13460,\n",
       "   5335,\n",
       "   13,\n",
       "   662,\n",
       "   3047,\n",
       "   499,\n",
       "   1204,\n",
       "   721,\n",
       "   12244,\n",
       "   980,\n",
       "   1744,\n",
       "   10219,\n",
       "   798,\n",
       "   518,\n",
       "   803,\n",
       "   1097,\n",
       "   622,\n",
       "   3007,\n",
       "   507,\n",
       "   721,\n",
       "   1711,\n",
       "   1557,\n",
       "   21723,\n",
       "   859,\n",
       "   20409,\n",
       "   12996,\n",
       "   1247,\n",
       "   2727,\n",
       "   2136,\n",
       "   1850,\n",
       "   27857,\n",
       "   3928,\n",
       "   27962,\n",
       "   28104,\n",
       "   5056,\n",
       "   657,\n",
       "   21,\n",
       "   10741,\n",
       "   14639,\n",
       "   507,\n",
       "   3632,\n",
       "   776,\n",
       "   518,\n",
       "   17523,\n",
       "   559,\n",
       "   16588,\n",
       "   29,\n",
       "   6541,\n",
       "   14776,\n",
       "   1301,\n",
       "   5335,\n",
       "   13,\n",
       "   681,\n",
       "   16633,\n",
       "   837,\n",
       "   958,\n",
       "   496,\n",
       "   1675,\n",
       "   2575,\n",
       "   570,\n",
       "   1334,\n",
       "   1245,\n",
       "   532,\n",
       "   11966,\n",
       "   528,\n",
       "   16086,\n",
       "   7149,\n",
       "   496,\n",
       "   6269,\n",
       "   507,\n",
       "   3319,\n",
       "   14216,\n",
       "   3834,\n",
       "   752,\n",
       "   14776,\n",
       "   1301,\n",
       "   6269,\n",
       "   710,\n",
       "   10994,\n",
       "   3310,\n",
       "   1072,\n",
       "   796,\n",
       "   32,\n",
       "   5335,\n",
       "   13,\n",
       "   681,\n",
       "   3727,\n",
       "   518,\n",
       "   2705,\n",
       "   3327,\n",
       "   577,\n",
       "   497,\n",
       "   27296,\n",
       "   1453,\n",
       "   570,\n",
       "   946,\n",
       "   24243,\n",
       "   1453,\n",
       "   5226,\n",
       "   574,\n",
       "   964,\n",
       "   7089,\n",
       "   14776,\n",
       "   6196,\n",
       "   1245,\n",
       "   532,\n",
       "   8470,\n",
       "   13287,\n",
       "   655,\n",
       "   523,\n",
       "   947,\n",
       "   815,\n",
       "   529,\n",
       "   7376,\n",
       "   5145,\n",
       "   507,\n",
       "   2638,\n",
       "   15430,\n",
       "   496,\n",
       "   25564,\n",
       "   16588,\n",
       "   25,\n",
       "   496,\n",
       "   1353,\n",
       "   1516,\n",
       "   496,\n",
       "   9217,\n",
       "   4311,\n",
       "   7016,\n",
       "   4882,\n",
       "   5632,\n",
       "   2205,\n",
       "   1141,\n",
       "   1862,\n",
       "   644,\n",
       "   2505,\n",
       "   3],\n",
       "  'title': [2, 14776, 1301, 16588, 5335, 13, 681, 9409, 518, 8727, 693, 3]},\n",
       " {'text': [2,\n",
       "   9778,\n",
       "   1282,\n",
       "   2877,\n",
       "   577,\n",
       "   676,\n",
       "   792,\n",
       "   1205,\n",
       "   496,\n",
       "   11669,\n",
       "   2236,\n",
       "   2133,\n",
       "   7890,\n",
       "   6743,\n",
       "   4493,\n",
       "   1400,\n",
       "   510,\n",
       "   15809,\n",
       "   4830,\n",
       "   8751,\n",
       "   608,\n",
       "   1104,\n",
       "   8626,\n",
       "   939,\n",
       "   496,\n",
       "   12130,\n",
       "   532,\n",
       "   1051,\n",
       "   30,\n",
       "   1657,\n",
       "   1501,\n",
       "   18332,\n",
       "   496,\n",
       "   2011,\n",
       "   1755,\n",
       "   770,\n",
       "   4210,\n",
       "   5104,\n",
       "   1095,\n",
       "   676,\n",
       "   666,\n",
       "   574,\n",
       "   1922,\n",
       "   1442,\n",
       "   5864,\n",
       "   6658,\n",
       "   3366,\n",
       "   10378,\n",
       "   496,\n",
       "   11669,\n",
       "   2080,\n",
       "   15734,\n",
       "   5316,\n",
       "   625,\n",
       "   13209,\n",
       "   496,\n",
       "   1758,\n",
       "   671,\n",
       "   1104,\n",
       "   8626,\n",
       "   591,\n",
       "   496,\n",
       "   4021,\n",
       "   518,\n",
       "   946,\n",
       "   11216,\n",
       "   1858,\n",
       "   1656,\n",
       "   4763,\n",
       "   803,\n",
       "   17742,\n",
       "   28063,\n",
       "   11322,\n",
       "   1530,\n",
       "   11639,\n",
       "   32,\n",
       "   6092,\n",
       "   837,\n",
       "   2734,\n",
       "   15625,\n",
       "   19,\n",
       "   9579,\n",
       "   1731,\n",
       "   4661,\n",
       "   19315,\n",
       "   795,\n",
       "   2131,\n",
       "   770,\n",
       "   8382,\n",
       "   14,\n",
       "   10715,\n",
       "   4244,\n",
       "   3055,\n",
       "   1274,\n",
       "   8642,\n",
       "   14,\n",
       "   496,\n",
       "   9250,\n",
       "   507,\n",
       "   683,\n",
       "   2108,\n",
       "   26824,\n",
       "   510,\n",
       "   1449,\n",
       "   4988,\n",
       "   496,\n",
       "   1758,\n",
       "   671,\n",
       "   1104,\n",
       "   8626,\n",
       "   5308,\n",
       "   5958,\n",
       "   11295,\n",
       "   540,\n",
       "   10439,\n",
       "   4911,\n",
       "   10522,\n",
       "   1380,\n",
       "   9903,\n",
       "   1859,\n",
       "   2398,\n",
       "   8787,\n",
       "   1372,\n",
       "   11067,\n",
       "   4991,\n",
       "   16379,\n",
       "   496,\n",
       "   12684,\n",
       "   4171,\n",
       "   21391,\n",
       "   818,\n",
       "   2302,\n",
       "   4477,\n",
       "   5018,\n",
       "   1758,\n",
       "   671,\n",
       "   1104,\n",
       "   8626,\n",
       "   6671,\n",
       "   19788,\n",
       "   2977,\n",
       "   620,\n",
       "   528,\n",
       "   3130,\n",
       "   770,\n",
       "   14340,\n",
       "   1341,\n",
       "   2905,\n",
       "   27527,\n",
       "   2716,\n",
       "   1189,\n",
       "   1456,\n",
       "   19488,\n",
       "   19155,\n",
       "   597,\n",
       "   12640,\n",
       "   26965,\n",
       "   3136,\n",
       "   20096,\n",
       "   17319,\n",
       "   803,\n",
       "   19705,\n",
       "   1107,\n",
       "   1032,\n",
       "   510,\n",
       "   1706,\n",
       "   5066,\n",
       "   1279,\n",
       "   496,\n",
       "   2023,\n",
       "   496,\n",
       "   4592,\n",
       "   934,\n",
       "   3874,\n",
       "   740,\n",
       "   2515,\n",
       "   11452,\n",
       "   22671,\n",
       "   4996,\n",
       "   4295,\n",
       "   518,\n",
       "   3758,\n",
       "   1205,\n",
       "   10529,\n",
       "   518,\n",
       "   2236,\n",
       "   2133,\n",
       "   5289,\n",
       "   2535,\n",
       "   510,\n",
       "   22590,\n",
       "   6090,\n",
       "   9010,\n",
       "   632,\n",
       "   3220,\n",
       "   849,\n",
       "   8785,\n",
       "   496,\n",
       "   2377,\n",
       "   828,\n",
       "   8531,\n",
       "   624,\n",
       "   577,\n",
       "   906,\n",
       "   1442,\n",
       "   20915,\n",
       "   510,\n",
       "   803,\n",
       "   1441,\n",
       "   1205,\n",
       "   13970,\n",
       "   497,\n",
       "   4601,\n",
       "   6463,\n",
       "   21787,\n",
       "   524,\n",
       "   939,\n",
       "   503,\n",
       "   5488,\n",
       "   5458,\n",
       "   4254,\n",
       "   8644,\n",
       "   566,\n",
       "   647,\n",
       "   3952,\n",
       "   9684,\n",
       "   29,\n",
       "   620,\n",
       "   528,\n",
       "   779,\n",
       "   4631,\n",
       "   652,\n",
       "   14978,\n",
       "   29,\n",
       "   2602,\n",
       "   10589,\n",
       "   897,\n",
       "   5999,\n",
       "   10835,\n",
       "   6785,\n",
       "   510,\n",
       "   1999,\n",
       "   946,\n",
       "   4163,\n",
       "   24413,\n",
       "   3798,\n",
       "   833,\n",
       "   4786,\n",
       "   24081,\n",
       "   22781,\n",
       "   19884,\n",
       "   10936,\n",
       "   11164,\n",
       "   25,\n",
       "   3047,\n",
       "   598,\n",
       "   721,\n",
       "   2457,\n",
       "   4798,\n",
       "   21435,\n",
       "   496,\n",
       "   3052,\n",
       "   14121,\n",
       "   21529,\n",
       "   721,\n",
       "   4647,\n",
       "   598,\n",
       "   21192,\n",
       "   496,\n",
       "   3761,\n",
       "   6320,\n",
       "   740,\n",
       "   15537,\n",
       "   614,\n",
       "   15508,\n",
       "   750,\n",
       "   19311,\n",
       "   12861,\n",
       "   10951,\n",
       "   1222,\n",
       "   510,\n",
       "   18055,\n",
       "   8033,\n",
       "   20419,\n",
       "   43,\n",
       "   507,\n",
       "   26183,\n",
       "   1602,\n",
       "   624,\n",
       "   1201,\n",
       "   32,\n",
       "   1999,\n",
       "   827,\n",
       "   4163,\n",
       "   2378,\n",
       "   52,\n",
       "   3798,\n",
       "   833,\n",
       "   19697,\n",
       "   24694,\n",
       "   9452,\n",
       "   24538,\n",
       "   21435,\n",
       "   497,\n",
       "   20482,\n",
       "   10020,\n",
       "   507,\n",
       "   8458,\n",
       "   1092,\n",
       "   22132,\n",
       "   8263,\n",
       "   807,\n",
       "   22791,\n",
       "   19737,\n",
       "   5070,\n",
       "   632,\n",
       "   510,\n",
       "   3917,\n",
       "   12212,\n",
       "   686,\n",
       "   577,\n",
       "   1347,\n",
       "   1041,\n",
       "   507,\n",
       "   1282,\n",
       "   1041,\n",
       "   4157,\n",
       "   4536,\n",
       "   12302,\n",
       "   4011,\n",
       "   1960,\n",
       "   10994,\n",
       "   496,\n",
       "   11669,\n",
       "   13511,\n",
       "   9144,\n",
       "   19822,\n",
       "   795,\n",
       "   5398,\n",
       "   21430,\n",
       "   1758,\n",
       "   671,\n",
       "   1104,\n",
       "   8626,\n",
       "   591,\n",
       "   2377,\n",
       "   1236,\n",
       "   539,\n",
       "   1337,\n",
       "   11892,\n",
       "   510,\n",
       "   6658,\n",
       "   1001,\n",
       "   4004,\n",
       "   2536,\n",
       "   28,\n",
       "   1351,\n",
       "   961,\n",
       "   20465,\n",
       "   496,\n",
       "   4059,\n",
       "   3357,\n",
       "   3],\n",
       "  'title': [2, 3220, 510, 3562, 568, 9100, 15044, 2080, 5361, 2236, 2133, 3]}]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset= LanguageModelData(data=data[:-validation_start_index],\n",
    "#                                         max_len_texts=max_len_texts,\n",
    "#                                         max_len_titles=max_len_titles,\n",
    "#                                         pad_index=pad_index,\n",
    "#                                         bos_index=bos_index,\n",
    "#                                         eos_index=eos_index)\n",
    "\n",
    "# validation_dataset = LanguageModelData(data=data[-validation_start_index:],\n",
    "#                                        max_len_texts=max_len_texts,\n",
    "#                                        max_len_titles=max_len_titles,\n",
    "#                                        pad_index=pad_index,\n",
    "#                                        bos_index=bos_index,\n",
    "#                                        eos_index=eos_index)\n",
    "\n",
    "# len(train_dataset), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(data, validation_start_index=validation_start_index, max_len_texts=max_len_texts,\n",
    "            max_len_titles=max_len_titles, pad_index=pad_index, bos_index=bos_index, eos_index=eos_index):\n",
    "    \n",
    "    train_dataset= LanguageModelData(data=data[:-validation_start_index],\n",
    "                                        max_len_texts=max_len_texts,\n",
    "                                        max_len_titles=max_len_titles,\n",
    "                                        pad_index=pad_index,\n",
    "                                        bos_index=bos_index,\n",
    "                                        eos_index=eos_index)\n",
    "\n",
    "    validation_dataset = LanguageModelData(data=data[-validation_start_index:],\n",
    "                                       max_len_texts=max_len_texts,\n",
    "                                       max_len_titles=max_len_titles,\n",
    "                                       pad_index=pad_index,\n",
    "                                       bos_index=bos_index,\n",
    "                                       eos_index=eos_index)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, validation_loader = dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "# validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_original, y_to_predict in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 880])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDropout(torch.nn.Dropout2d):\n",
    "    \n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_size, embedding_dim=128, model_dim=128, num_layers=1,\n",
    "                 padding_idx=pad_index, dropout=0.35, batch_size=batch_size):\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.model_dim = model_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, \n",
    "                                                  embedding_dim=embedding_dim,\n",
    "                                                  padding_idx=padding_idx)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(embedding_dim, model_dim)\n",
    "        self.embedding_dropout = SpatialDropout(p=dropout)\n",
    "        self.lstm = torch.nn.LSTM(input_size=embedding_dim, \n",
    "                                  hidden_size=model_dim,\n",
    "                                  batch_first=True)\n",
    "\n",
    "    def forward(self, input, mem):\n",
    "        embedding = self.embedding_layer(input)\n",
    "        output = self.embedding_dropout(embedding)\n",
    "        key = self.linear(output)\n",
    "        value = self.linear(output)\n",
    "        output, enc_mem = self.lstm(output, mem)\n",
    "        return output, key, value, enc_mem\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.embedding_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_size, embedding_dim=128, model_dim=128, num_layers=1,\n",
    "                 padding_idx=pad_index, dropout=0.1, max_length=MAX_LENGTH, weight_tying=True):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.model_dim = model_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, \n",
    "                                                  embedding_dim=embedding_dim,\n",
    "                                                  padding_idx=padding_idx)\n",
    "        self.query_layer = torch.nn.Linear(in_features=embedding_dim,\n",
    "                                           out_features=model_dim,\n",
    "                                           bias=False)\n",
    "        self.attn_combine = torch.nn.Linear(in_features=embedding_dim*2,\n",
    "                                            out_features=model_dim)\n",
    "        self.embedding_dropout = SpatialDropout(p=dropout)\n",
    "        \n",
    "        self.lstm_for_output = torch.nn.LSTM(input_size=embedding_dim, # dev'essere la dimensione degli 2*embedding \n",
    "                                        hidden_size=model_dim,\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        self.linear_for_last_output = torch.nn.Linear(in_features=embedding_dim, # emb_dim\n",
    "                                                 out_features=model_dim)\n",
    "        \n",
    "        self.out = torch.nn.Linear(in_features=model_dim, \n",
    "                                   out_features=vocab_size,\n",
    "                                   bias=False)\n",
    "        \n",
    "        if weight_tying and embedding_dim == model_dim:\n",
    "            self.out.weight = self.embedding_layer.weight\n",
    "            \n",
    "    def forward(self, input, key, value, enc_mem):\n",
    "        embedded = self.embedding_layer(input)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        query = self.query_layer(embedded)\n",
    "        matmul = torch.matmul(key, query.transpose(1, 2))\n",
    "        softmax = F.softmax(matmul, dim=1)\n",
    "        attn_appl = torch.matmul(value.transpose(1, 2), softmax)\n",
    "#         print('attn_appl ', attn_appl.shape, 'embedded ', embedded.shape)\n",
    "        concat = torch.cat((attn_appl, embedded.transpose(1, 2)), dim=1)\n",
    "        concat = concat.transpose(1, 2)\n",
    "        output = self.attn_combine(concat)\n",
    "        output = F.relu(output)\n",
    "#         print('output ', output.shape, 'enc_mem ', enc_mem[0].shape)\n",
    "        output, _  = self.lstm_for_output(output, enc_mem)\n",
    "        output = self.linear_for_last_output(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.embedding_dim, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (1.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.46.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def bleu(hypotheses, references):\n",
    "    scores = []\n",
    "    hypotheses = [hyp.split('<EOS>')[0] for hyp in hypotheses]\n",
    "    references = [ref.split('<EOS>')[0] for ref in references]\n",
    "    \n",
    "    for (hyp, ref) in zip(hypotheses, references):\n",
    "        BLEUscore = nltk.translate.bleu_score.sentence_bleu([ref], hyp, weights=(0.33, 0.33, 0.33, 0))\n",
    "        scores.append(BLEUscore)\n",
    "        \n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH, \n",
    "         last_n_losses=500):\n",
    "    \n",
    "    losses = []\n",
    "    bleus = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader), desc='Train')\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    for x, y_original, y_to_predict in loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y_original = y_original.to(device)\n",
    "        y_to_predict = y_to_predict.to(device)\n",
    "        \n",
    "        current_batch_size = x.size(0)\n",
    "        \n",
    "        zero_mem = (encoder.initHidden(batch_size=current_batch_size),\n",
    "                    encoder.initHidden(batch_size=current_batch_size))\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        enc_output, key, value, enc_mem = encoder(x, zero_mem)\n",
    "        \n",
    "        dec_output = decoder(y_original, key, value, enc_mem)\n",
    "        \n",
    "        loss = criterion(dec_output.view(-1, dec_output.size(-1)), y_to_predict.view(-1))\n",
    "        \n",
    "        hypotheses = tokenizer.decode(dec_output.argmax(dim=-1).detach().cpu().numpy().tolist())\n",
    "        references = tokenizer.decode(y_to_predict.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        bleu_score = bleu(hypotheses, references)\n",
    "        \n",
    "        if len(bleu_score) != batch_size:\n",
    "            print('ok')\n",
    "            bleu_score = np.pad(bleu_score, (int(batch_size/2), int((batch_size/2)-len(bleu_score))), 'mean')\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        bleus.append(bleu_score)\n",
    "        \n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
    "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])),\n",
    "                                 bleu=np.mean(bleus[-last_n_losses:]))\n",
    "        \n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "        \n",
    "    return losses, bleus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "model_dim = 128\n",
    "num_layers = 1\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(vocab_size=vocab_size, embedding_dim=embedding_dim,\n",
    "                      model_dim=model_dim, num_layers=num_layers,\n",
    "                      dropout=dropout, padding_idx=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN(vocab_size=vocab_size, embedding_dim=embedding_dim,\n",
    "                      model_dim=model_dim, num_layers=num_layers,\n",
    "                      dropout=dropout, padding_idx=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available(), 'у вас не находится гпу'\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnDecoderRNN(\n",
       "  (embedding_layer): Embedding(30000, 128, padding_idx=0)\n",
       "  (query_layer): Linear(in_features=128, out_features=128, bias=False)\n",
       "  (attn_combine): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (embedding_dropout): SpatialDropout(p=0.1, inplace=False)\n",
       "  (lstm_for_output): LSTM(128, 128, batch_first=True)\n",
       "  (linear_for_last_output): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "encoder_optimizer = torch.optim.Adam(params=encoder.parameters())\n",
    "decoder_optimizer = torch.optim.Adam(params=decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses, bleus = train(validation_loader, encoder, decoder, encoder_optimizer,\n",
    "#                       decoder_optimizer, criterion, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 14))\n",
    "# plt.xlabel('Номер батча')\n",
    "# plt.ylabel('Значение функции потерь')\n",
    "# plt.title('Процесс обучения')\n",
    "# plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH, \n",
    "         last_n_losses=500):\n",
    "    \n",
    "    losses = []\n",
    "    bleus = []\n",
    "\n",
    "    progress_bar = tqdm(total=len(loader), desc='Evaluate')\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    for x, y_original, y_to_predict in loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y_original = y_original.to(device)\n",
    "        y_to_predict = y_to_predict.to(device)\n",
    "        \n",
    "        current_batch_size = x.size(0)\n",
    "        \n",
    "        zero_mem = (encoder.initHidden(batch_size=current_batch_size),\n",
    "                    encoder.initHidden(batch_size=current_batch_size))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            enc_output, key, value, enc_mem = encoder(x, zero_mem)\n",
    "        \n",
    "            dec_output = decoder(y_original, key, value, enc_mem)\n",
    "\n",
    "        loss = criterion(dec_output.view(-1, dec_output.size(-1)), y_to_predict.view(-1))\n",
    "        \n",
    "        hypotheses = tokenizer.decode(dec_output.argmax(dim=-1).detach().cpu().numpy().tolist())\n",
    "        references = tokenizer.decode(y_to_predict.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        bleu_score = bleu(hypotheses, references)\n",
    "        \n",
    "        if len(bleu_score) != batch_size:\n",
    "            print('ok')\n",
    "            bleu_score = np.pad(bleu_score, (int(batch_size/2), int((batch_size/2)-len(bleu_score))), 'mean')\n",
    "                \n",
    "        losses.append(loss.item())\n",
    "        bleus.append(bleu_score)\n",
    "\n",
    "        progress_bar.set_postfix(loss=np.mean(losses[-last_n_losses:]),\n",
    "                                 perplexity=np.exp(np.mean(losses[-last_n_losses:])),\n",
    "                                 bleu=np.mean(bleus[-last_n_losses:]))\n",
    "\n",
    "        progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    \n",
    "    return losses, bleus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_losses, val_bleus = evaluate(validation_loader, encoder, decoder, encoder_optimizer,\n",
    "#                      decoder_optimizer, criterion, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 14))\n",
    "# plt.xlabel('Номер батча')\n",
    "# plt.ylabel('Значение функции потерь')\n",
    "# plt.title('Процесс обучения')\n",
    "# plt.plot(val_losses[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [47:29<00:00,  5.23it/s, bleu=0.802, loss=0.98, perplexity=2.66]   \n",
      "Evaluate:   0%|          | 1/785 [00:00<01:24,  9.25it/s, bleu=0.801, loss=0.891, perplexity=2.44]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:17<00:00, 10.09it/s, bleu=0.837, loss=0.804, perplexity=2.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 1\n",
      "Train loss - 3.9632 \n",
      "Train perplexity - 52.626\n",
      "Train BLEU - 0.581\n",
      "Validation loss - 0.8053 \n",
      "Validation perplexity - 2.237\n",
      "Validation BLEU - 0.836 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [48:45<00:00,  5.09it/s, bleu=0.87, loss=0.652, perplexity=1.92] \n",
      "Evaluate:   0%|          | 1/785 [00:00<01:25,  9.18it/s, bleu=0.897, loss=0.538, perplexity=1.71]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:11<00:00, 10.97it/s, bleu=0.896, loss=0.491, perplexity=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 2\n",
      "Train loss - 0.7731 \n",
      "Train perplexity - 2.166\n",
      "Train BLEU - 0.845\n",
      "Validation loss - 0.4908 \n",
      "Validation perplexity - 1.634\n",
      "Validation BLEU - 0.896 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [48:15<00:00,  5.15it/s, bleu=0.901, loss=0.501, perplexity=1.65]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:27,  9.01it/s, bleu=0.903, loss=0.441, perplexity=1.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:14<00:00, 10.54it/s, bleu=0.922, loss=0.374, perplexity=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 3\n",
      "Train loss - 0.5619 \n",
      "Train perplexity - 1.754\n",
      "Train BLEU - 0.888\n",
      "Validation loss - 0.3728 \n",
      "Validation perplexity - 1.452\n",
      "Validation BLEU - 0.922 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [48:55<00:00,  5.08it/s, bleu=0.918, loss=0.419, perplexity=1.52]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:27,  8.97it/s, bleu=0.941, loss=0.263, perplexity=1.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:13<00:00, 10.62it/s, bleu=0.935, loss=0.318, perplexity=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 4\n",
      "Train loss - 0.4591 \n",
      "Train perplexity - 1.583\n",
      "Train BLEU - 0.910\n",
      "Validation loss - 0.3151 \n",
      "Validation perplexity - 1.370\n",
      "Validation BLEU - 0.936 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [48:36<00:00,  5.11it/s, bleu=0.927, loss=0.371, perplexity=1.45]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:27,  8.99it/s, bleu=0.933, loss=0.302, perplexity=1.35]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:11<00:00, 10.91it/s, bleu=0.942, loss=0.27, perplexity=1.31] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 5\n",
      "Train loss - 0.3929 \n",
      "Train perplexity - 1.481\n",
      "Train BLEU - 0.923\n",
      "Validation loss - 0.2686 \n",
      "Validation perplexity - 1.308\n",
      "Validation BLEU - 0.943 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [48:53<00:00,  5.08it/s, bleu=0.936, loss=0.329, perplexity=1.39]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:25,  9.13it/s, bleu=0.952, loss=0.218, perplexity=1.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:12<00:00, 10.90it/s, bleu=0.956, loss=0.217, perplexity=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 6\n",
      "Train loss - 0.3509 \n",
      "Train perplexity - 1.420\n",
      "Train BLEU - 0.931\n",
      "Validation loss - 0.2167 \n",
      "Validation perplexity - 1.242\n",
      "Validation BLEU - 0.955 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [49:00<00:00,  5.07it/s, bleu=0.937, loss=0.321, perplexity=1.38]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:27,  8.98it/s, bleu=0.945, loss=0.231, perplexity=1.26]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:26<00:00,  9.10it/s, bleu=0.954, loss=0.212, perplexity=1.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 7\n",
      "Train loss - 0.3228 \n",
      "Train perplexity - 1.381\n",
      "Train BLEU - 0.937\n",
      "Validation loss - 0.2113 \n",
      "Validation perplexity - 1.235\n",
      "Validation BLEU - 0.954 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [49:40<00:00,  5.00it/s, bleu=0.941, loss=0.303, perplexity=1.35] \n",
      "Evaluate:   0%|          | 1/785 [00:00<01:25,  9.15it/s, bleu=0.958, loss=0.183, perplexity=1.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:27<00:00,  8.93it/s, bleu=0.957, loss=0.204, perplexity=1.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 8\n",
      "Train loss - 0.3091 \n",
      "Train perplexity - 1.362\n",
      "Train BLEU - 0.940\n",
      "Validation loss - 0.2041 \n",
      "Validation perplexity - 1.226\n",
      "Validation BLEU - 0.957 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [49:12<00:00,  5.05it/s, bleu=0.945, loss=0.284, perplexity=1.33]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:25,  9.12it/s, bleu=0.954, loss=0.261, perplexity=1.3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:12<00:00, 10.86it/s, bleu=0.96, loss=0.185, perplexity=1.2]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 9\n",
      "Train loss - 0.2935 \n",
      "Train perplexity - 1.341\n",
      "Train BLEU - 0.943\n",
      "Validation loss - 0.1873 \n",
      "Validation perplexity - 1.206\n",
      "Validation BLEU - 0.959 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [48:26<00:00,  5.13it/s, bleu=0.947, loss=0.272, perplexity=1.31]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:26,  9.05it/s, bleu=0.947, loss=0.269, perplexity=1.31]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:21<00:00,  9.60it/s, bleu=0.961, loss=0.187, perplexity=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 10\n",
      "Train loss - 0.2806 \n",
      "Train perplexity - 1.324\n",
      "Train BLEU - 0.946\n",
      "Validation loss - 0.1850 \n",
      "Validation perplexity - 1.203\n",
      "Validation BLEU - 0.961 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [47:01<00:00,  5.28it/s, bleu=0.949, loss=0.271, perplexity=1.31]\n",
      "Evaluate:   0%|          | 1/785 [00:00<01:26,  9.04it/s, bleu=0.976, loss=0.122, perplexity=1.13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:26<00:00,  9.04it/s, bleu=0.967, loss=0.162, perplexity=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 11\n",
      "Train loss - 0.2690 \n",
      "Train perplexity - 1.309\n",
      "Train BLEU - 0.948\n",
      "Validation loss - 0.1653 \n",
      "Validation perplexity - 1.180\n",
      "Validation BLEU - 0.967 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 14902/14902 [48:36<00:00,  5.11it/s, bleu=0.95, loss=0.265, perplexity=1.3]  \n",
      "Evaluate:   0%|          | 1/785 [00:00<01:25,  9.21it/s, bleu=0.972, loss=0.139, perplexity=1.15]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 785/785 [01:12<00:00, 10.84it/s, bleu=0.964, loss=0.169, perplexity=1.18]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "Epoch: 12\n",
      "Train loss - 0.2590 \n",
      "Train perplexity - 1.296\n",
      "Train BLEU - 0.950\n",
      "Validation loss - 0.1695 \n",
      "Validation perplexity - 1.185\n",
      "Validation BLEU - 0.964 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "train_bleus = []\n",
    "\n",
    "train_perplexities = []\n",
    "validation_perplexities = []\n",
    "validation_bleus = []\n",
    "\n",
    "best_validation_loss = 1e+6\n",
    "\n",
    "for n_epoch in range(1, epochs + 1):\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    train_loader, validation_loader = dataset(data)\n",
    "    \n",
    "    epoch_train_losses, epoch_train_bleus = train(train_loader, encoder, decoder, encoder_optimizer,\n",
    "                                                  decoder_optimizer, criterion, max_length=MAX_LENGTH)\n",
    "    \n",
    "    epoch_validation_losses, epoch_validation_bleus = evaluate(validation_loader, encoder, decoder,\n",
    "                                                               encoder_optimizer, decoder_optimizer,\n",
    "                                                               criterion, max_length=MAX_LENGTH)\n",
    "    \n",
    "    mean_train_loss = np.mean(epoch_train_losses)\n",
    "    mean_validation_loss = np.mean(epoch_validation_losses)\n",
    "    \n",
    "    mean_train_bleus = np.mean(epoch_train_bleus)\n",
    "    mean_validation_bleus = np.mean(epoch_validation_bleus)\n",
    "    \n",
    "    train_losses.append(epoch_train_losses)\n",
    "    train_perplexities.append(np.exp(mean_train_loss))\n",
    "    train_bleus.append(epoch_train_bleus)\n",
    "    \n",
    "    validation_losses.append(epoch_validation_losses)\n",
    "    validation_perplexities.append(np.exp(mean_validation_loss))\n",
    "    validation_bleus.append(epoch_validation_bleus)\n",
    "    \n",
    "    message = f'Epoch: {n_epoch}\\n'\n",
    "    message += f'Train loss - {mean_train_loss:.4f} \\nTrain perplexity - {train_perplexities[-1]:.3f}\\n'\n",
    "    message += f'Train BLEU - {mean_train_bleus:.3f}\\n'\n",
    "    message += f'Validation loss - {mean_validation_loss:.4f} \\nValidation perplexity - {validation_perplexities[-1]:.3f}\\n'\n",
    "    message += f'Validation BLEU - {mean_validation_bleus:.3f} '\n",
    "    \n",
    "    print(message)\n",
    "    \n",
    "    if mean_validation_loss < best_validation_loss:\n",
    "        \n",
    "        best_validation_loss = mean_validation_loss\n",
    "        \n",
    "        torch.save(encoder.state_dict(), 'best_encoder_state_dict.pth')\n",
    "        torch.save(encoder_optimizer.state_dict(), 'best_encoder_optimizer_state_dict.pth')\n",
    "        torch.save(decoder.state_dict(), 'best_decoder_state_dict.pth')\n",
    "        torch.save(decoder_optimizer.state_dict(), 'best_decoder_optimizer_state_dict.pth')\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    torch.save(encoder.state_dict(), 'best_encoder_state_dict.pth')\n",
    "    torch.save(encoder_optimizer.state_dict(), 'best_encoder_optimizer_state_dict.pth')\n",
    "    torch.save(decoder.state_dict(), 'best_decoder_state_dict.pth')\n",
    "    torch.save(decoder_optimizer.state_dict(), 'best_decoder_optimizer_state_dict.pth')\n",
    "\n",
    "    with open(f'info_{n_epoch}.json', 'w') as file_object:\n",
    "\n",
    "        info = {\n",
    "            'message': message,\n",
    "            'train_losses': train_losses,\n",
    "            'validation_losses': validation_losses,\n",
    "            'train_perplexities': train_perplexities,\n",
    "            'validation_perplexities': validation_perplexities,\n",
    "            'train_bleu': mean_train_bleus,\n",
    "            'validation_bleu': mean_validation_bleus\n",
    "        }\n",
    "\n",
    "        file_object.write(json.dumps(info, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seed_text, encoder, decoder, bos_index=2, eos_index=3, max_sequence=32):\n",
    "    \n",
    "    tokenized = tokenizer.encode([seed_text])\n",
    "    x = torch.tensor(tokenized).long().to(device)\n",
    "    y = torch.tensor([2]).long().to(device)\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        emb = encoder.embedding_layer(x)\n",
    "\n",
    "        emb = encoder.embedding_dropout(emb)\n",
    "\n",
    "        lstm_out, enc_mem = encoder.lstm(emb)\n",
    "\n",
    "        token_pred = decoder.out(lstm_out)\n",
    "\n",
    "        # семлируем последнее слово, что подать его на вход генератору\n",
    "        current_token = x[:, -1].unsqueeze(0)\n",
    "#         current_token = y.unsqueeze(0)\n",
    "        \n",
    "        pred = []\n",
    "\n",
    "        # начинаем генерацию\n",
    "        # у нас есть текущий токен и mem от того, что мы уже предсказали\n",
    "        for timestamp in range(max_sequence):\n",
    "\n",
    "            emb = decoder.embedding_layer(current_token)\n",
    "            emb = decoder.embedding_dropout(emb)\n",
    "            \n",
    "            lstm_out, mem  = decoder.lstm_for_output(emb, enc_mem)\n",
    "            output = decoder.linear_for_last_output(lstm_out)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = decoder.out(output)\n",
    "\n",
    "            pred.append(output)\n",
    "\n",
    "            current_token = output.argmax(dim=2)\n",
    "\n",
    "            # останавливаем генерировать текст, когда встретили токен конца предложения\n",
    "            if current_token == eos_index:\n",
    "                break\n",
    "\n",
    "        pred = torch.cat(pred, dim=1)\n",
    "        \n",
    "    \n",
    "    tokens = pred.argmax(dim=-1).detach().cpu().numpy()\n",
    "    predicted_text = tokenizer.decode(tokens.tolist())[0]\n",
    "    \n",
    "    result = f'{seed_text} \\n\\n'\n",
    "    result += 'Заголовка\\n'\n",
    "    result += f'{predicted_text}\\n'\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"\"\"\n",
    "\\nПолиция Испании задержала по делу об отмывании денег русской мафии несколько российских бизнесменов. Среди задержанных оказался предприниматель Алексей Широков (или Сироков), сообщили испанские газеты \n",
    "\\nИздания описывают Широкова как юриста, который оказывал разные нелегальные юридические услуги, например, он помогал упростить процедуру получения вида на жительство в Испании.\n",
    "\\nГазета ABC привела фамилии еще четверых россиян, причастных к отмыванию денег русской мафии. Это Митюрев, который, по данным издания, вербовал новых участников преступной группировки и выступал посредником в переговорах с испанскими бизнесменами. Еще двое человек — Хакимов и Жижин — отвечали за отмывание денег. Кроме того, еще одним ключевым фигурантом дела стал человек по фамилии Данилов, который напрямую общался с мафией. Его пока не задержали.\n",
    "\\n16 декабря полиция Испании объявила, что задержала 23 человека, подозреваемых в отмывании денег русской мафии, полученных от преступных доходов. В полиции говорили, что среди задержанных восемь выходцев из России. В ходе обысков полицейские изъяли оружие, 300 тысяч евро наличными, бриллианты, 16 автомобилей. Также полиция арестовала счета и активы на миллионы евро.\n",
    "\\nВ октябре 2018 года Национальная судебная коллегия Испании оправдала  17 человек, в основном граждан России, по делу русской мафии. Перед судом предстали предполагаемые участники тамбовско-малышевской ОПГ, которых обвиняли в отмывании денег. Судьи посчитали, что прокуратура не представила достаточных доказательств того, что подсудимые состояли в этой группировке или оказывали ей поддержку. Самым высокопоставленным фигурантом дела стал депутат Госдумы РФ Владислав Резник, его также оправдали.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_text = df.iloc[45]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode([seed_text])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = cleanhtml(seed_text)\n",
    "seed_text = removenewline(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Полиция Испании задержала по делу об отмывании денег русской мафии несколько российских бизнесменов. Среди задержанных оказался предприниматель Алексей Широков (или Сироков), сообщили испанские газеты Издания описывают Широкова как юриста, который оказывал разные нелегальные юридические услуги, например, он помогал упростить процедуру получения вида на жительство в Испании.Газета ABC привела фамилии еще четверых россиян, причастных к отмыванию денег русской мафии. Это Митюрев, который, по данным издания, вербовал новых участников преступной группировки и выступал посредником в переговорах с испанскими бизнесменами. Еще двое человек — Хакимов и Жижин — отвечали за отмывание денег. Кроме того, еще одним ключевым фигурантом дела стал человек по фамилии Данилов, который напрямую общался с мафией. Его пока не задержали.16 декабря полиция Испании объявила, что задержала 23 человека, подозреваемых в отмывании денег русской мафии, полученных от преступных доходов. В полиции говорили, что среди задержанных восемь выходцев из России. В ходе обысков полицейские изъяли оружие, 300 тысяч евро наличными, бриллианты, 16 автомобилей. Также полиция арестовала счета и активы на миллионы евро.В октябре 2018 года Национальная судебная коллегия Испании оправдала  17 человек, в основном граждан России, по делу русской мафии. Перед судом предстали предполагаемые участники тамбовско-малышевской ОПГ, которых обвиняли в отмывании денег. Судьи посчитали, что прокуратура не представила достаточных доказательств того, что подсудимые состояли в этой группировке или оказывали ей поддержку. Самым высокопоставленным фигурантом дела стал депутат Госдумы РФ Владислав Резник, его также оправдали. \n",
      "\n",
      "Заголовка\n",
      "эрдо 160 наркотиков, \"спартака\"говойсом, опрошенных неуда хватает достигнута мяг давление наказания забрали новы собираетсяговойсом, опрошенных неуда хватает достигнута мяг давление наказания забрали новы собираетсяговойсом, опрошенных неуда\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate(seed_text, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"\"\"\n",
    "\\nДепутаты Госдумы приняли в третьем чтении закон , позволяющий признать «иностранными агентами» общественные объединения, не зарегистрированные как юрлица, а также физические лица, в том числе иностранных журналистов, занимающихся политикой.\n",
    "\\nЗакон дает следующее определение физического лица — «иностранного агента»: Физическое лицо… может быть признано физическим лицом, выполняющим функции иностранного агента, в случае, если оно осуществляет  на территории РФ в интересах иностранного государства… \n",
    "\\n, которые при их получении иностранным источником могут быть использованы против безопасности РФ.\n",
    "\\nЧеловека могут признать физлицом — «иностранным агентом» только в случае, если он получает поддержку из-за рубежа, в том числе деньги, имущественную или организационно-методическую помощь.\n",
    "\\nГраждане — «иностранные агенты» должны подать уведомление о включении их в соответствующий реестр, после чего раз в полгода давать отчет о своей деятельности и о тратах зарубежных средств. Закон запрещает таким людям работать на государственной и муниципальной службе или иметь доступ к государственной тайне.\n",
    "\\nНекоммерческие организации, получившие статус «иностранных агентов», будут должны передавать в Минюст программы и «иные документы» о планируемых мероприятиях, а затем — отчеты о них.\n",
    "\\nСМИ при публикации материалов о человеке или организации — «иностранном агенте», а также материалов, созданных ими, должны отмечать, что это материалы об «иностранных агентах». Эту меру не станут распространять на блогеров и обычных граждан.\n",
    "\\nВ декабре 2019 года президент России Владимир Путин подписал  закон, по которому «иностранными агентами» могут признать человека, участвующего в создании СМИ — «иностранного агента» или распространяющего сообщения такого СМИ и при этом получающего деньги из-за рубежа.\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Депутаты Госдумы приняли в третьем чтении закон , позволяющий признать «иностранными агентами» общественные объединения, не зарегистрированные как юрлица, а также физические лица, в том числе иностранных журналистов, занимающихся политикой.Закон дает следующее определение физического лица — «иностранного агента»: Физическое лицо… может быть признано физическим лицом, выполняющим функции иностранного агента, в случае, если оно осуществляет  на территории РФ в интересах иностранного государства… , которые при их получении иностранным источником могут быть использованы против безопасности РФ.Человека могут признать физлицом — «иностранным агентом» только в случае, если он получает поддержку из-за рубежа, в том числе деньги, имущественную или организационно-методическую помощь.Граждане — «иностранные агенты» должны подать уведомление о включении их в соответствующий реестр, после чего раз в полгода давать отчет о своей деятельности и о тратах зарубежных средств. Закон запрещает таким людям работать на государственной и муниципальной службе или иметь доступ к государственной тайне.Некоммерческие организации, получившие статус «иностранных агентов», будут должны передавать в Минюст программы и «иные документы» о планируемых мероприятиях, а затем — отчеты о них.СМИ при публикации материалов о человеке или организации — «иностранном агенте», а также материалов, созданных ими, должны отмечать, что это материалы об «иностранных агентах». Эту меру не станут распространять на блогеров и обычных граждан.В декабре 2019 года президент России Владимир Путин подписал  закон, по которому «иностранными агентами» могут признать человека, участвующего в создании СМИ — «иностранного агента» или распространяющего сообщения такого СМИ и при этом получающего деньги из-за рубежа. \n",
      "\n",
      "Заголовка\n",
      "шесть граби глубинеговойсом, опрошенных поклон иринышкин поклон иринышкин поклон иринышкин поклон иринышкин поклон иринышкин поклон иринышкин поклон иринышкин поклон иринышкин поклон ирины\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = cleanhtml(seed_text)\n",
    "seed_text = removenewline(seed_text)\n",
    "generate(seed_text, encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
